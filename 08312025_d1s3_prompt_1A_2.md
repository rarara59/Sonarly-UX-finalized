# Claude Code Prompt: TokenBucket Rate Limiting Accuracy Fix

## OBJECTIVE
Fix TokenBucket rate limiting accuracy from 87% to 95%+ by implementing quantized time windows instead of imprecise continuous timing.

## CURRENT PROBLEM
**File**: `src/detection/transport/token-bucket.js`
**Issue**: Rate limiting accuracy is 87% (target 95%+) due to JavaScript timer precision issues
**Root Cause**: Floating-point timing calculations with system timer jitter

## SPECIFIC IMPLEMENTATION TASK

### Target File Modifications
**Primary File**: `src/detection/transport/token-bucket.js`
**Test File**: `scripts/test-token-bucket.js` (for validation)

### Code Changes Required

**REPLACE** the current imprecise `refillTokens()` method:
```javascript
// CURRENT (BROKEN - 87% accuracy):
refillTokens() {
  const now = Date.now();
  const timeDelta = now - this.lastRefill; // Imprecise timing
  const tokensToAdd = (timeDelta / this.ratePeriod) * this.rateLimit;
  // Results in timer jitter and floating-point errors
}
```

**WITH** quantized time window approach:
```javascript
// TARGET (95%+ accuracy):
refillTokens() {
  const now = Date.now();
  const windowsSinceRefill = Math.floor((now - this.lastRefill) / this.rateWindow);
  
  if (windowsSinceRefill >= 1) {
    const tokensToAdd = windowsSinceRefill * this.tokensPerWindow;
    this.tokens = Math.min(this.maxTokens, this.tokens + tokensToAdd);
    this.lastRefill += (windowsSinceRefill * this.rateWindow); // Exact timing
  }
}
```

### Required Constructor Changes

**ADD** to constructor to support quantized windows:
```javascript
constructor(config) {
  // ... existing code ...
  
  // NEW: Quantized timing support
  this.rateWindow = config.rateWindow || 100; // 100ms windows
  this.tokensPerWindow = Math.floor(this.rateLimit * (this.rateWindow / this.ratePeriod));
  
  // ... rest of existing code ...
}
```

### Additional Method Updates

**MODIFY** `canConsume()` to call refill before every check:
```javascript
canConsume(tokens = 1) {
  this.refillTokens(); // CRITICAL: Refill before every check
  return this.tokens >= tokens;
}
```

## INCREMENTAL TESTING PROTOCOL

### Step 1: Backup and Modify
```bash
# Backup current working version
cp src/detection/transport/token-bucket.js src/detection/transport/token-bucket.js.backup

# Implement quantized timing changes
# (Make the three code changes above)
```

### Step 2: Unit Test Validation
```bash
# Run existing test suite
node scripts/test-token-bucket.js

# Look for these specific improvements:
# - Rate limiting accuracy: Should be 95%+ (currently 87%)
# - Token consumption tests: Should pass with higher accuracy
# - Burst mode: Should still work correctly
```

### Step 3: Accuracy Measurement Test
**CREATE** specific accuracy test in `scripts/test-token-bucket.js`:
```javascript
// Add this test case:
async function testRateLimitingAccuracy() {
  const bucket = new TokenBucket({
    rateLimit: 100,
    ratePeriod: 1000,
    rateWindow: 50  // 50ms quantized windows
  });
  
  // Test over 10 seconds with precise timing
  const startTime = Date.now();
  let allowedRequests = 0;
  let totalRequests = 0;
  
  while ((Date.now() - startTime) < 10000) {
    totalRequests++;
    if (bucket.canConsume()) {
      bucket.consume();
      allowedRequests++;
    }
    await new Promise(resolve => setTimeout(resolve, 9)); // ~111 rps attempt rate
  }
  
  const actualRate = (allowedRequests / 10); // requests per second
  const accuracy = (actualRate / 100) * 100; // percentage accuracy
  
  console.log(`Rate accuracy: ${accuracy.toFixed(1)}% (target: 95%+)`);
  return accuracy >= 95;
}
```

### Step 4: Performance Regression Test
```bash
# Verify performance hasn't degraded
# Check that latency is still <1ms per token check
node scripts/test-token-bucket.js | grep -E "(latency|performance)"
```

## SUCCESS CRITERIA

### Performance Requirements (Must Meet All)
1. **Rate Limiting Accuracy**: 95%+ (up from 87%)
2. **Token Check Latency**: <1ms per check (maintain current performance)
3. **Memory Usage**: No increase from current baseline
4. **Burst Mode**: Still functional with 2x capacity for 10 seconds
5. **All Existing Tests**: Must pass (10/13 currently, target 13/13)

### Validation Commands
```bash
# Primary validation
node scripts/test-token-bucket.js

# Look for these specific outputs:
# ✅ Rate limiting accuracy: 95%+ (target: 95%+)
# ✅ Token check latency: <1ms average
# ✅ All tests passed: 13/13 (up from 10/13)
```

## ROLLBACK PROCEDURE
If accuracy doesn't improve or performance degrades:
```bash
# Restore backup
cp src/detection/transport/token-bucket.js.backup src/detection/transport/token-bucket.js

# Verify rollback works
node scripts/test-token-bucket.js
```

## TECHNICAL IMPLEMENTATION DETAILS

### Key Algorithm Changes
1. **Quantized Windows**: Use discrete 50-100ms time windows instead of continuous timing
2. **Exact Timing**: Update `lastRefill` to exact window boundaries, not current time
3. **Integer Math**: Avoid floating-point calculations that introduce precision errors

### Why This Fixes the Problem
- **Timer Jitter Elimination**: Quantized windows absorb small timing variations
- **Predictable Behavior**: Integer math produces consistent results
- **Exact Synchronization**: Window boundaries align with token distribution

### Configuration Options
```javascript
// Optimal configuration for trading systems:
const tokenBucket = new TokenBucket({
  rateLimit: 100,           // requests per second
  ratePeriod: 1000,         // 1 second periods
  rateWindow: 50,           // 50ms quantized windows
  burstCapacity: 200        // 2x burst capacity
});
```

## EXPECTED OUTCOME
- **Before**: 87% rate limiting accuracy with timer precision issues
- **After**: 95%+ accuracy using quantized time windows and integer math
- **Benefit**: More reliable rate limiting during high-frequency trading scenarios

## IMPLEMENTATION FOCUS
**Single Task**: Fix timing precision in TokenBucket class only
**No Scope Creep**: Don't modify other components or orchestration
**Measure Results**: Use the existing test suite to validate improvements
**Trading Impact**: More accurate rate limiting = better handling of viral meme coin scenarios