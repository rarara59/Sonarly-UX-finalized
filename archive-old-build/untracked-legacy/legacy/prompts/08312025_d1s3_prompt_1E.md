PROMPT 1E: Request Cache Extraction
SINGLE FOCUS: Extract request deduplication and caching from existing 2000-line RPC connection pool
EXPLICIT FILE PATHS:

Source: src/detection/transport/rpc-connection-pool.js (cache, dedupe, coalescing, TTL sections)
Target: src/detection/transport/request-cache.js

INCREMENTAL IMPLEMENTATION PROCESS:
Step 1: Extract cache key generation, storage, and TTL management logic
Step 2: Create RequestCache class with caching, TTL expiration, and request coalescing methods
Step 3: Test cache hit/miss accuracy with various TTL configurations and request patterns
Step 4: Test request coalescing for duplicate in-flight requests (multiple callers, single backend call)
Step 5: Create integration stub in original file: await this.cache.get(key, fetcher)
CLEAR SUCCESS CRITERIA:
Caching Requirements:

Cache hit rate: 70%+ for typical meme coin trading request patterns
TTL expiration accuracy: Entries expire within 5% of configured TTL duration
Request coalescing: Duplicate in-flight requests return same Promise result
Memory bounds: LRU eviction prevents unbounded cache growth beyond configured limits

Performance Requirements:

Cache lookup time: <1ms per get() operation including key generation and lookup
Memory usage limit: Configurable maximum entries (default: 10,000) with LRU eviction
Request coalescing efficiency: 95%+ reduction in duplicate RPC calls for identical requests
TTL cleanup performance: Expired entries cleaned within 60 seconds of expiration

Integration Requirements:

Original file compiles successfully after extraction with integration stub
Integration interface: await this.cache.get(key, fetcher) ready for orchestrator use
Export functionality: import { RequestCache } from './request-cache.js' works correctly
Configuration compatibility: Existing cache TTL configuration environment variables preserved

REQUIREMENTS-BASED VALIDATION:
Measure These Metrics:

Cache hit rate percentage (target: 70%+ with realistic trading request patterns)
TTL expiration accuracy (target: Within 5% of configured expiration time)
Duplicate request reduction (target: 95%+ reduction for identical concurrent calls)
Memory usage bounds compliance (target: Within configured limits with LRU eviction)
Cache lookup latency (target: <1ms per get() operation)