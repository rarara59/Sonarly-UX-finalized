# Corrected Real Network Testing Suite - Claude Code Optimized

## OVERVIEW
Six corrected prompts for authentic validation using real Solana network conditions. Incorporates technical corrections for concurrent scheduling, proper API usage, WebSocket transport, chaos injection, and competitive edge measurement.

**Key Corrections Applied**:
- Concurrent event replay with in-flight caps
- Time-window pagination instead of slot loops
- WebSocket client for streaming subscriptions
- HTTP adapter-level chaos injection
- Edge scoreboard proving competitive advantage

---

# PROMPT RN1-CORRECTED: Historical LP Event Replay with Edge Measurement

## SINGLE FOCUS
Validate meme coin detection pipeline using concurrent historical LP event replay with competitive edge measurement

## EXPLICIT FILE PATHS
- **CREATE**: `scripts/test-historical-replay-corrected.js`
- **CREATE**: `scripts/concurrent-event-replayer.js`
- **CREATE**: `scripts/edge-scoreboard.js`
- **CREATE**: `data/historical-lp-events.ndjson` (data file)
- **CREATE**: `results/edge-analysis-results.json` (output)
- **IMPORT**: Complete refactored RPC system

## INCREMENTAL IMPLEMENTATION

### Step 1: Concurrent Event Replayer Implementation
Create replayer with in-flight task management to prevent timer storms:
```javascript
class ConcurrentEventReplayer {
  constructor(maxInFlight = 2000) {
    this.maxInFlight = maxInFlight;
    this.activeTimers = 0;
    this.eventQueue = [];
    this.processedEvents = [];
  }
  
  async replayEvents(events, speedMultiplier = 1.0) {
    const baseTime = new Date(events[0].timestamp);
    
    events.forEach(event => {
      const eventTime = new Date(event.timestamp);
      const replayDelay = (eventTime - baseTime) / speedMultiplier;
      this.scheduleEventWithBackoff(event, replayDelay);
    });
    
    await this.waitForCompletion();
    return this.processedEvents;
  }
  
  scheduleEventWithBackoff(event, delay) {
    if (this.activeTimers >= this.maxInFlight) {
      this.eventQueue.push({ event, delay });
      return;
    }
    
    setTimeout(async () => {
      try {
        const result = await this.processEvent(event);
        this.processedEvents.push(result);
      } finally {
        this.activeTimers--;
        this.processQueuedEvents();
      }
    }, delay);
    
    this.activeTimers++;
  }
  
  processQueuedEvents() {
    while (this.eventQueue.length > 0 && this.activeTimers < this.maxInFlight) {
      const { event, delay } = this.eventQueue.shift();
      this.scheduleEventWithBackoff(event, delay);
    }
  }
}
```

### Step 2: Edge Scoreboard Implementation
Create competitive advantage measurement system:
```javascript
class EdgeScoreboard {
  constructor() {
    this.edgeResults = [];
    this.retailBaselineMs = {
      p50: 180000,  // 3 minutes estimated
      p95: 420000   // 7 minutes estimated
    };
  }
  
  recordDetection(lpEvent, detectionResult) {
    const lpCreateTime = new Date(lpEvent.timestamp);
    const detectionTime = new Date(detectionResult.timestamp);
    
    const ourLatencyMs = detectionTime - lpCreateTime;
    const retailLatencyMs = this.estimateRetailDetection(lpEvent);
    const edgeSeconds = (retailLatencyMs - ourLatencyMs) / 1000;
    
    this.edgeResults.push({
      lpCreateTime,
      detectionTime,
      ourLatencyMs,
      retailLatencyMs,
      edgeSeconds,
      capturedWithin30s: ourLatencyMs <= 30000
    });
  }
  
  generateEdgeSummary() {
    const ourLatencies = this.edgeResults.map(r => r.ourLatencyMs);
    const edgeSeconds = this.edgeResults.map(r => r.edgeSeconds);
    const captureRate = this.edgeResults.filter(r => r.capturedWithin30s).length / this.edgeResults.length;
    
    return {
      events_total: this.edgeResults.length,
      our_detection_latency_ms: {
        p50: this.calculatePercentile(ourLatencies, 0.5),
        p95: this.calculatePercentile(ourLatencies, 0.95)
      },
      retail_detection_latency_ms: this.retailBaselineMs,
      edge_seconds: {
        median: this.calculatePercentile(edgeSeconds, 0.5),
        p95: this.calculatePercentile(edgeSeconds, 0.95)
      },
      opportunity_capture_≤30s_pct: Math.round(captureRate * 100)
    };
  }
  
  estimateRetailDetection(lpEvent) {
    // Simulate retail trader delay (3-7 minutes)
    return Math.random() * (420000 - 180000) + 180000;
  }
}
```

### Step 3: Historical Data Collection
Export LP events with canonical timestamps:
```javascript
const historicalLPEvents = [
  {
    timestamp: '2024-08-15T18:05:12.123Z',  // Precise LP creation time
    signature: 'abc123...',
    programId: 'RAYDIUM_AMM_V4',
    instruction: 'initialize',
    mint: 'BONK_MINT_ADDRESS',
    pool: 'POOL_ADDRESS',
    lpAmount: '1000000000',
    eventId: `lp_${Date.now()}_${Math.random()}` // Canonical ID
  }
  // ... 100+ events from high-activity period
];
```

### Step 4: Concurrent Detection Pipeline Test
Process events through detection system with concurrency control:
```javascript
async processEvent(lpEvent) {
  const startTime = Date.now();
  
  try {
    // Run through complete detection pipeline
    const enrichmentData = await this.enrichWithMainnetData(lpEvent);
    const riskAnalysis = await this.analyzeRiskFactors(enrichmentData);
    const tradingSignal = await this.generateTradingSignal(riskAnalysis);
    
    const detectionTime = Date.now();
    const processingTimeMs = detectionTime - startTime;
    
    // Record edge measurement
    this.edgeScoreboard.recordDetection(lpEvent, {
      timestamp: new Date(detectionTime),
      signal: tradingSignal,
      processingTimeMs
    });
    
    return {
      eventId: lpEvent.eventId,
      success: true,
      processingTimeMs,
      signal: tradingSignal
    };
    
  } catch (error) {
    return {
      eventId: lpEvent.eventId,
      success: false,
      error: error.message,
      processingTimeMs: Date.now() - startTime
    };
  }
}
```

### Step 5: Multi-Speed Testing
Test at both 1x and 5x speeds with separate edge measurements:
```javascript
async runMultiSpeedTest(events) {
  // 1x speed test
  console.log('Running 1x speed replay...');
  const oneXResults = await this.replayer.replayEvents(events, 1.0);
  const oneXEdge = this.edgeScoreboard.generateEdgeSummary();
  
  // Reset for 5x test
  this.edgeScoreboard.reset();
  
  // 5x speed test
  console.log('Running 5x speed replay...');
  const fiveXResults = await this.replayer.replayEvents(events, 5.0);
  const fiveXEdge = this.edgeScoreboard.generateEdgeSummary();
  
  return {
    oneX: { results: oneXResults, edge: oneXEdge },
    fiveX: { results: fiveXResults, edge: fiveXEdge }
  };
}
```

### Step 6: Results Analysis and Validation
Generate comprehensive results with competitive advantage proof:
```javascript
const finalResults = {
  test_summary: {
    events_total: historicalEvents.length,
    processed_≤30s_1x_pct: oneXResults.filter(r => r.processingTimeMs <= 30000).length / oneXResults.length * 100,
    processed_≤30s_5x_pct: fiveXResults.filter(r => r.processingTimeMs <= 30000).length / fiveXResults.length * 100,
    silent_drops: oneXResults.filter(r => !r.success && !r.error).length,
    circuit_breaker_trips: this.circuitBreakerMonitor.getTripCount()
  },
  competitive_edge: {
    oneX_speed: oneXEdge,
    fiveX_speed: fiveXEdge,
    competitive_advantage_proven: oneXEdge.edge_seconds.median >= 120 // ≥2 minutes faster
  },
  component_health: this.getComponentHealthSummary()
};
```

## CLEAR SUCCESS CRITERIA
- 99% of events processed within 30 seconds at 1x speed
- 80% of events processed within 30 seconds at 5x speed
- Zero silent drops (all events generate result or logged error)
- Edge median ≥120 seconds faster than retail detection
- Circuit breaker trips <5% of events with automatic recovery

## REQUIREMENTS-BASED VALIDATION
- **Processing Speed**: ≥99% within 30s at 1x, ≥80% at 5x speed
- **Reliability**: Zero silent drops, all events accounted for
- **Competitive Edge**: Median edge ≥120 seconds vs retail detection
- **System Stability**: Circuit breaker trips <5% with recovery
- **Concurrency Control**: No timer storms, max 2000 in-flight tasks
- **Memory Efficiency**: <100MB growth during replay test

---

# PROMPT RN2-CORRECTED: Time-Window Slot Scanning Test

## SINGLE FOCUS
Validate RPC pool performance using proper time-window pagination with baseline-relative performance gates

## EXPLICIT FILE PATHS
- **CREATE**: `scripts/test-time-window-scan-corrected.js`
- **CREATE**: `scripts/time-window-scanner.js`
- **CREATE**: `results/time-scan-baseline.json` (baseline output)
- **CREATE**: `results/time-scan-results.json` (test output)
- **IMPORT**: RPC pool components from refactored system

## INCREMENTAL IMPLEMENTATION

### Step 1: Time-Window Scanner Implementation
Replace slot loops with proper signature pagination:
```javascript
class TimeWindowScanner {
  constructor(rpcPool) {
    this.rpcPool = rpcPool;
    this.metrics = {
      getSignaturesForAddress: [],
      getTransaction: [],
      errors: new Map()
    };
  }
  
  async scanTimeWindow(programId, startTime, endTime) {
    let cursor = null;
    const allTransactions = [];
    let totalSignatures = 0;
    
    while (true) {
      const sigStartTime = Date.now();
      
      try {
        const signatures = await this.rpcPool.call('getSignaturesForAddress', [
          programId,
          {
            limit: 1000,
            before: cursor,
            until: null
          }
        ]);
        
        const sigLatency = Date.now() - sigStartTime;
        this.metrics.getSignaturesForAddress.push(sigLatency);
        
        if (signatures.length === 0) break;
        
        // Filter by time window
        const filteredSigs = signatures.filter(sig => 
          sig.blockTime >= startTime && sig.blockTime <= endTime
        );
        
        // Process transactions with proper versioning
        for (const sig of filteredSigs) {
          const txResult = await this.getTransactionWithMetrics(sig.signature);
          if (txResult.transaction) {
            allTransactions.push(txResult.transaction);
          }
        }
        
        totalSignatures += signatures.length;
        
        // Check if we've passed the time window
        const lastBlockTime = signatures[signatures.length - 1].blockTime;
        if (lastBlockTime < startTime) break;
        
        // Update cursor for next page
        cursor = signatures[signatures.length - 1].signature;
        
      } catch (error) {
        this.recordError('getSignaturesForAddress', error);
        break;
      }
    }
    
    return { transactions: allTransactions, totalSignatures };
  }
  
  async getTransactionWithMetrics(signature) {
    const startTime = Date.now();
    
    try {
      const transaction = await this.rpcPool.call('getTransaction', [
        signature,
        {
          maxSupportedTransactionVersion: 0,
          encoding: 'json'
        }
      ]);
      
      const latency = Date.now() - startTime;
      this.metrics.getTransaction.push(latency);
      
      return { transaction, latency, success: true };
      
    } catch (error) {
      const latency = Date.now() - startTime;
      this.recordError('getTransaction', error);
      
      return { transaction: null, latency, success: false, error };
    }
  }
}
```

### Step 2: Baseline Performance Measurement
Establish performance baseline before main test:
```javascript
async measurePerformanceBaseline() {
  console.log('Measuring performance baseline...');
  
  const baselineStartTime = Math.floor(Date.now() / 1000) - 7200; // 2 hours ago
  const baselineEndTime = Math.floor(Date.now() / 1000) - 3600;   // 1 hour ago
  
  const baselineResults = await this.scanner.scanTimeWindow(
    'RAYDIUM_AMM_V4',
    baselineStartTime,
    baselineEndTime
  );
  
  const baseline = {
    timestamp: new Date().toISOString(),
    duration_seconds: 3600,
    transactions_found: baselineResults.transactions.length,
    signatures_processed: baselineResults.totalSignatures,
    getSignaturesForAddress_latency: {
      p50: this.calculatePercentile(this.scanner.metrics.getSignaturesForAddress, 0.5),
      p95: this.calculatePercentile(this.scanner.metrics.getSignaturesForAddress, 0.95),
      p99: this.calculatePercentile(this.scanner.metrics.getSignaturesForAddress, 0.99)
    },
    getTransaction_latency: {
      p50: this.calculatePercentile(this.scanner.metrics.getTransaction, 0.5),
      p95: this.calculatePercentile(this.scanner.metrics.getTransaction, 0.95),
      p99: this.calculatePercentile(this.scanner.metrics.getTransaction, 0.99)
    },
    success_rate: this.calculateSuccessRate()
  };
  
  // Save baseline for comparison
  await this.saveBaseline(baseline);
  return baseline;
}
```

### Step 3: Error Categorization System
Properly categorize all RPC errors for analysis:
```javascript
recordError(method, error) {
  const errorKey = `${method}_${this.categorizeError(error)}`;
  const count = this.metrics.errors.get(errorKey) || 0;
  this.metrics.errors.set(errorKey, count + 1);
}

categorizeError(error) {
  const message = error.message?.toLowerCase() || '';
  
  if (message.includes('timeout') || error.code === 'TIMEOUT') return 'TIMEOUT';
  if (message.includes('connection reset') || error.code === 'ECONNRESET') return 'CONN_RESET';
  if (message.includes('rate limit') || error.code === 429) return 'RATE_LIMIT';
  if (error.code >= 500) return 'SERVER_5XX';
  if (error.code >= 400 && error.code < 500) return 'CLIENT_4XX';
  if (message.includes('json') || message.includes('parse')) return 'INVALID_JSON';
  if (message.includes('circuit') || message.includes('breaker')) return 'CB_OPEN';
  
  return 'UNKNOWN';
}
```

### Step 4: Baseline-Relative Performance Gates
Compare performance against measured baseline rather than absolute values:
```javascript
async validatePerformanceAgainstBaseline(testResults, baseline) {
  const testLatency = {
    getSignaturesForAddress_p95: this.calculatePercentile(this.scanner.metrics.getSignaturesForAddress, 0.95),
    getTransaction_p95: this.calculatePercentile(this.scanner.metrics.getTransaction, 0.95)
  };
  
  const performanceGates = {
    success_rate: testResults.success_rate >= 0.99,
    getSignaturesForAddress_p95_relative: testLatency.getSignaturesForAddress_p95 <= baseline.getSignaturesForAddress_latency.p95 * 1.2,
    getTransaction_p95_relative: testLatency.getTransaction_p95 <= baseline.getTransaction_latency.p95 * 1.2,
    error_rate: testResults.error_rate <= 0.01,
    circuit_breaker_stable: this.getCircuitBreakerTrips() < 10
  };
  
  const allPassed = Object.values(performanceGates).every(gate => gate === true);
  
  return {
    gates: performanceGates,
    all_passed: allPassed,
    baseline_comparison: {
      p95_improvement_pct: ((baseline.getTransaction_latency.p95 - testLatency.getTransaction_p95) / baseline.getTransaction_latency.p95 * 100).toFixed(1)
    }
  };
}
```

### Step 5: Comprehensive Metrics Collection
Track separate metrics for each RPC method:
```javascript
generateComprehensiveResults() {
  const results = {
    test_summary: {
      start_time: this.testStartTime.toISOString(),
      duration_minutes: (Date.now() - this.testStartTime) / 60000,
      transactions_processed: this.processedTransactions,
      total_requests: this.metrics.getSignaturesForAddress.length + this.metrics.getTransaction.length
    },
    performance_by_method: {
      getSignaturesForAddress: {
        requests: this.metrics.getSignaturesForAddress.length,
        latency_ms: {
          p50: this.calculatePercentile(this.metrics.getSignaturesForAddress, 0.5),
          p95: this.calculatePercentile(this.metrics.getSignaturesForAddress, 0.95),
          p99: this.calculatePercentile(this.metrics.getSignaturesForAddress, 0.99),
          max: Math.max(...this.metrics.getSignaturesForAddress)
        }
      },
      getTransaction: {
        requests: this.metrics.getTransaction.length,
        latency_ms: {
          p50: this.calculatePercentile(this.metrics.getTransaction, 0.5),
          p95: this.calculatePercentile(this.metrics.getTransaction, 0.95),
          p99: this.calculatePercentile(this.metrics.getTransaction, 0.99),
          max: Math.max(...this.metrics.getTransaction)
        }
      }
    },
    errors_by_category: Object.fromEntries(this.metrics.errors)
  };
  
  return results;
}
```

### Step 6: Circuit Breaker Integration Testing
Monitor circuit breaker behavior during sustained scanning:
```javascript
monitorCircuitBreakerDuringTest() {
  const monitor = {
    transitions: [],
    tripCount: 0,
    recoveryTimes: []
  };
  
  this.circuitBreaker.on('stateChange', (from, to, endpoint) => {
    monitor.transitions.push({
      timestamp: Date.now(),
      from,
      to,
      endpoint,
      reason: this.circuitBreaker.getLastError()?.message
    });
    
    if (to === 'OPEN') monitor.tripCount++;
  });
  
  return monitor;
}
```

## CLEAR SUCCESS CRITERIA
- Success rate ≥99% for all RPC calls
- P95 latency ≤baseline × 1.2 for both getSignaturesForAddress and getTransaction
- Error rate <1% with proper error categorization
- Circuit breaker transitions <10 during scan

## REQUIREMENTS-BASED VALIDATION
- **Success Rate**: ≥99% of all RPC requests successful
- **Relative Performance**: P95 latency ≤120% of measured baseline
- **Error Handling**: All errors categorized, <1% total error rate
- **API Correctness**: Proper maxSupportedTransactionVersion usage
- **Circuit Breaker**: <10 trips with successful recovery
- **Memory Efficiency**: <200MB total memory during scan

---

# PROMPT RN3-CORRECTED: WebSocket Live Streaming Test

## SINGLE FOCUS
Validate streaming stability using proper WebSocket client with fixed-interval monitoring

## EXPLICIT FILE PATHS
- **CREATE**: `scripts/test-websocket-streaming-corrected.js`
- **CREATE**: `scripts/websocket-stream-monitor.js`
- **CREATE**: `results/streaming-soak-results.json` (output)
- **IMPORT**: Detection pipeline from refactored system
- **IMPORT**: `@solana/web3.js` for WebSocket Connection

## INCREMENTAL IMPLEMENTATION

### Step 1: WebSocket Client Setup
Use proper WebSocket Connection instead of HTTP RPC calls:
```javascript
import { Connection, PublicKey } from '@solana/web3.js';

class WebSocketStreamTest {
  constructor(wsEndpoint, detectionSystem) {
    this.wsConnection = new Connection(wsEndpoint, {
      wsEndpoint: wsEndpoint.replace('https:', 'wss:'),
      commitment: 'processed'
    });
    this.detectionSystem = detectionSystem;
    this.subscriptions = [];
    this.streamMetrics = {
      eventsReceived: 0,
      eventsProcessed: 0,
      eventsDropped: 0,
      processingErrors: 0
    };
  }
  
  async setupProgramLogSubscriptions() {
    try {
      // Subscribe to Raydium AMM v4 logs
      const raydiumSub = this.wsConnection.onLogs(
        new PublicKey('RAYDIUM_AMM_V4_PROGRAM_ID'),
        (logs, context) => {
          this.handleLogEvent('raydium', logs, context);
        },
        'processed'
      );
      
      // Subscribe to SPL Token program logs
      const tokenSub = this.wsConnection.onLogs(
        new PublicKey('SPL_TOKEN_PROGRAM_ID'),
        (logs, context) => {
          this.handleLogEvent('token', logs, context);
        },
        'processed'
      );
      
      this.subscriptions = [raydiumSub, tokenSub];
      console.log('WebSocket subscriptions established:', this.subscriptions);
      
      return { raydiumSub, tokenSub };
      
    } catch (error) {
      console.error('Failed to setup WebSocket subscriptions:', error);
      throw error;
    }
  }
}
```

### Step 2: Stream Processing with Queue Management
Process log events with backpressure monitoring:
```javascript
class StreamProcessor {
  constructor(maxQueueSize = 10000) {
    this.processingQueue = [];
    this.maxQueueSize = maxQueueSize;
    this.processing = false;
    this.queueStats = {
      maxDepth: 0,
      avgDepth: 0,
      samples: []
    };
  }
  
  async handleLogEvent(source, logs, context) {
    this.streamMetrics.eventsReceived++;
    
    // Check for backpressure
    if (this.processingQueue.length >= this.maxQueueSize) {
      this.streamMetrics.eventsDropped++;
      console.warn('Queue full, dropping event:', {
        queueDepth: this.processingQueue.length,
        source
      });
      return;
    }
    
    // Add to processing queue
    this.processingQueue.push({
      timestamp: Date.now(),
      source,
      logs,
      context,
      slot: context.slot
    });
    
    // Start processing if not already running
    if (!this.processing) {
      this.startProcessing();
    }
  }
  
  async startProcessing() {
    this.processing = true;
    
    while (this.processingQueue.length > 0) {
      const event = this.processingQueue.shift();
      await this.processLogEventSafely(event);
    }
    
    this.processing = false;
  }
  
  async processLogEventSafely(event) {
    const startTime = Date.now();
    
    try {
      // Parse log event
      const parsed = await this.parseLogEvent(event.logs);
      
      // Enrich with 1-2 RPC calls
      const enriched = await this.enrichEventData(parsed, event.context);
      
      // Run through detection pipeline
      await this.detectionSystem.processEvent(enriched);
      
      this.streamMetrics.eventsProcessed++;
      
    } catch (error) {
      this.streamMetrics.processingErrors++;
      console.error('Error processing log event:', error.message);
    }
    
    const processingTime = Date.now() - startTime;
    this.recordProcessingTime(processingTime);
  }
}
```

### Step 3: Fixed-Interval Monitoring System
Replace modulo sampling with proper setInterval:
```javascript
class StreamMonitor {
  constructor(streamProcessor) {
    this.streamProcessor = streamProcessor;
    this.monitoringActive = false;
    this.samples = [];
    this.startTime = Date.now();
    this.memoryBaseline = process.memoryUsage();
  }
  
  startMonitoring() {
    this.monitoringActive = true;
    
    // Sample every 30 seconds
    this.monitoringInterval = setInterval(() => {
      this.sampleMetrics();
    }, 30000);
    
    console.log('Stream monitoring started - sampling every 30 seconds');
  }
  
  sampleMetrics() {
    const currentTime = Date.now();
    const currentMemory = process.memoryUsage();
    const queueDepth = this.streamProcessor.processingQueue.length;
    
    const sample = {
      timestamp: currentTime,
      elapsed_minutes: (currentTime - this.startTime) / 60000,
      queue_depth: {
        current: queueDepth,
        avg: this.calculateAverageQueueDepth(),
        max: this.streamProcessor.queueStats.maxDepth
      },
      stream_rates: {
        in_rate: this.calculateIncomingRate(),
        out_rate: this.calculateProcessingRate(),
        drop_rate: this.calculateDropRate()
      },
      memory: {
        rss_mb: Math.round(currentMemory.rss / 1024 / 1024),
        heap_used_mb: Math.round(currentMemory.heapUsed / 1024 / 1024),
        growth_mb: Math.round((currentMemory.rss - this.memoryBaseline.rss) / 1024 / 1024)
      },
      circuit_breaker: {
        state: this.getCircuitBreakerState(),
        trips_total: this.getCircuitBreakerTrips()
      }
    };
    
    this.samples.push(sample);
    
    // Update queue stats
    this.streamProcessor.queueStats.maxDepth = Math.max(
      this.streamProcessor.queueStats.maxDepth,
      queueDepth
    );
    
    console.log('Stream sample:', sample);
  }
  
  stopMonitoring() {
    if (this.monitoringInterval) {
      clearInterval(this.monitoringInterval);
      this.monitoringActive = false;
      console.log('Stream monitoring stopped');
    }
  }
}
```

### Step 4: Backpressure Detection and Management
Monitor queue growth and processing rates:
```javascript
detectBackpressure() {
  const recentSamples = this.samples.slice(-5); // Last 5 samples (2.5 minutes)
  
  if (recentSamples.length < 3) return false;
  
  // Check for sustained queue growth
  const queueGrowthRate = this.calculateQueueGrowthRate(recentSamples);
  const avgProcessingRate = this.calculateAverageProcessingRate(recentSamples);
  const avgIncomingRate = this.calculateAverageIncomingRate(recentSamples);
  
  const backpressure = {
    detected: queueGrowthRate > 5 || avgIncomingRate > avgProcessingRate * 1.2,
    queue_growth_rate: queueGrowthRate,
    processing_rate: avgProcessingRate,
    incoming_rate: avgIncomingRate,
    queue_utilization: this.streamProcessor.processingQueue.length / this.streamProcessor.maxQueueSize
  };
  
  if (backpressure.detected) {
    console.warn('Backpressure detected:', backpressure);
  }
  
  return backpressure;
}
```

### Step 5: Circuit Breaker Monitoring During Stream
Track circuit breaker behavior throughout 60-minute test:
```javascript
monitorCircuitBreakerBehavior() {
  const cbMonitor = {
    transitions: [],
    tripsPerMinute: [],
    recoveryTimes: [],
    currentState: 'CLOSED'
  };
  
  // Monitor state changes
  this.circuitBreaker.on('stateChange', (from, to, endpoint) => {
    const transition = {
      timestamp: Date.now(),
      from,
      to,
      endpoint,
      reason: this.circuitBreaker.getLastError()?.message
    };
    
    cbMonitor.transitions.push(transition);
    cbMonitor.currentState = to;
    
    if (to === 'OPEN') {
      this.recordTripTime();
    } else if (from === 'HALF_OPEN' && to === 'CLOSED') {
      this.recordRecoveryTime(transition.timestamp);
    }
  });
  
  // Sample trips per minute
  setInterval(() => {
    const recentTrips = this.getTripsInLastMinute();
    cbMonitor.tripsPerMinute.push({
      timestamp: Date.now(),
      trips: recentTrips
    });
  }, 60000);
  
  return cbMonitor;
}
```

### Step 6: 60-Minute Soak Test with Stream Drop Detection
Run complete soak test with connection monitoring:
```javascript
async run60MinuteSoakTest() {
  const testDuration = 60 * 60 * 1000; // 60 minutes
  const startTime = Date.now();
  
  console.log('Starting 60-minute WebSocket soak test...');
  
  // Setup WebSocket subscriptions
  const subscriptions = await this.setupProgramLogSubscriptions();
  
  // Start monitoring
  this.streamMonitor.startMonitoring();
  const cbMonitor = this.monitorCircuitBreakerBehavior();
  
  // Monitor for connection drops
  this.wsConnection.onDisconnect(() => {
    console.warn('WebSocket connection dropped at:', new Date());
    this.streamMetrics.connectionDrops++;
  });
  
  // Run for full duration
  await new Promise(resolve => {
    setTimeout(resolve, testDuration);
  });
  
  // Cleanup
  this.streamMonitor.stopMonitoring();
  this.subscriptions.forEach(sub => {
    this.wsConnection.removeOnLogsListener(sub);
  });
  
  // Generate results
  return this.generateSoakTestResults(cbMonitor);
}

generateSoakTestResults(cbMonitor) {
  const totalEvents = this.streamMetrics.eventsReceived;
  const memoryGrowth = this.streamMonitor.getFinalMemoryGrowth();
  const dropRate = this.streamMetrics.eventsDropped / totalEvents;
  const tripsPerMinute = cbMonitor.tripsPerMinute.reduce((sum, sample) => sum + sample.trips, 0) / 60;
  
  return {
    test_duration_minutes: 60,
    stream_performance: {
      events_received: this.streamMetrics.eventsReceived,
      events_processed: this.streamMetrics.eventsProcessed,
      events_dropped: this.streamMetrics.eventsDropped,
      drop_rate_pct: Math.round(dropRate * 100),
      processing_success_rate_pct: Math.round((1 - this.streamMetrics.processingErrors / this.streamMetrics.eventsProcessed) * 100)
    },
    memory_analysis: {
      growth_mb: memoryGrowth,
      drift_mb_per_hour: memoryGrowth, // 60-minute test
      stable: memoryGrowth <= 50
    },
    queue_analysis: {
      max_depth: this.streamProcessor.queueStats.maxDepth,
      avg_depth: this.calculateAverageQueueDepth(),
      backpressure_events: this.countBackpressureEvents()
    },
    circuit_breaker_analysis: {
      total_transitions: cbMonitor.transitions.length,
      trips_per_minute_avg: tripsPerMinute,
      stable: tripsPerMinute <= 2,
      recovery_successful: cbMonitor.recoveryTimes.length > 0
    }
  };
}
```

## CLEAR SUCCESS CRITERIA
- Memory drift ≤50MB over 60 minutes
- Stream drop rate ≤1% (connection stability)
- Queue depth oscillates but drains (no unbounded growth)
- Circuit breaker trips ≤2 per minute with successful recovery
- Processing success rate ≥95% for received events

## REQUIREMENTS-BASED VALIDATION
- **Memory Stability**: RSS growth ≤50MB/hour, no memory leaks
- **Stream Reliability**: Drop rate ≤1%, stable WebSocket connections
- **Queue Management**: Max depth <500, drains within 60s of burst
- **Circuit Breaker**: ≤2 trips/minute, successful half-open recovery
- **Processing Success**: ≥95% of events processed without errors
- **Backpressure Handling**: System handles bursts without permanent queue growth

---

# PROMPT RN5-CORRECTED: HTTP Adapter Chaos Engineering Test

## SINGLE FOCUS
Validate circuit breaker and failover using HTTP adapter-level chaos injection with traffic distribution logging

## EXPLICIT FILE PATHS
- **CREATE**: `scripts/test-chaos-engineering-corrected.js`
- **CREATE**: `scripts/http-chaos-adapter.js`
- **CREATE**: `scripts/traffic-distribution-monitor.js`
- **CREATE**: `results/chaos-engineering-results.json` (output)
- **IMPORT**: Complete RPC pool with circuit breaker

## INCREMENTAL IMPLEMENTATION

### Step 1: HTTP Adapter Chaos Injection
Create chaos adapter at HTTP request level:
```javascript
class HTTPChaosAdapter {
  constructor(baseAdapter, chaosConfig = {}) {
    this.baseAdapter = baseAdapter;
    this.chaosConfig = {
      enabled: false,
      targetEndpoints: [],
      failureRate: 0.3,
      faultTypes: ['TIMEOUT', 'ECONNRESET', 'SERVER_ERROR'],
      delayJitterMs: { min: 0, max: 5000 },
      ...chaosConfig
    };
    this.chaosStats = {
      requestsIntercepted: 0,
      faultsInjected: 0,
      faultsByType: new Map()
    };
  }
  
  async request(url, options) {
    this.chaosStats.requestsIntercepted++;
    
    // Check if chaos should be applied to this endpoint
    if (this.shouldInjectChaos(url)) {
      return await this.injectChaos(url, options);
    }
    
    // Normal request through base adapter
    return await this.baseAdapter.request(url, options);
  }
  
  shouldInjectChaos(url) {
    if (!this.chaosConfig.enabled) return false;
    
    const matchesTarget = this.chaosConfig.targetEndpoints.some(target => 
      url.includes(target)
    );
    
    if (!matchesTarget) return false;
    
    return Math.random() < this.chaosConfig.failureRate;
  }
  
  async injectChaos(url, options) {
    this.chaosStats.faultsInjected++;
    
    const faultType = this.selectRandomFaultType();
    this.chaosStats.faultsByType.set(faultType, 
      (this.chaosStats.faultsByType.get(faultType) || 0) + 1
    );
    
    console.log(`Injecting ${faultType} fault for ${url}`);
    
    switch (faultType) {
      case 'TIMEOUT':
        // Simulate timeout
        await new Promise(resolve => setTimeout(resolve, 30000));
        throw new Error('Request timeout (chaos injected)');
        
      case 'ECONNRESET':
        // Simulate connection reset
        const error = new Error('Connection reset (chaos injected)');
        error.code = 'ECONNRESET';
        throw error;
        
      case 'SERVER_ERROR':
        // Simulate server error
        throw new Error('Internal server error (chaos injected)');
        
      case 'DELAY':
        // Inject random delay then succeed
        const delay = Math.random() * (this.chaosConfig.delayJitterMs.max - this.chaosConfig.delayJitterMs.min) + this.chaosConfig.delayJitterMs.min;
        await new Promise(resolve => setTimeout(resolve, delay));
        return await this.baseAdapter.request(url, options);
        
      default:
        return await this.baseAdapter.request(url, options);
    }
  }
  
  selectRandomFaultType() {
    const types = this.chaosConfig.faultTypes;
    return types[Math.floor(Math.random() * types.length)];
  }
}
```

### Step 2: Traffic Distribution Monitor
Track request distribution across endpoints before/during/after chaos:
```javascript
class TrafficDistributionMonitor {
  constructor(rpcPool) {
    this.rpcPool = rpcPool;
    this.trafficStats = new Map();
    this.samplingActive = false;
    this.samples = [];
  }
  
  startMonitoring() {
    this.samplingActive = true;
    this.resetStats();
    
    // Sample traffic distribution every 10 seconds
    this.samplingInterval = setInterval(() => {
      this.sampleTrafficDistribution();
    }, 10000);
    
    console.log('Traffic distribution monitoring started');
  }
  
  sampleTrafficDistribution() {
    const currentStats = this.rpcPool.getEndpointStats();
    const sample = {
      timestamp: Date.now(),
      distribution: {},
      total_requests: 0
    };
    
    // Calculate request counts per endpoint
    for (const [endpoint, stats] of currentStats) {
      sample.distribution[endpoint] = {
        requests: stats.requestCount,
        success_rate: stats.successCount / stats.requestCount,
        avg_latency: stats.avgLatency,
        circuit_state: stats.circuitState || 'CLOSED'
      };
      sample.total_requests += stats.requestCount;
    }
    
    // Calculate percentages
    for (const endpoint in sample.distribution) {
      sample.distribution[endpoint].percentage = 
        (sample.distribution[endpoint].requests / sample.total_requests * 100).toFixed(1);
    }
    
    this.samples.push(sample);
    console.log('Traffic distribution sample:', sample);
  }
  
  stopMonitoring() {
    if (this.samplingInterval) {
      clearInterval(this.samplingInterval);
      this.samplingActive = false;
      console.log('Traffic distribution monitoring stopped');
    }
  }
  
  getTrafficShiftAnalysis() {
    if (this.samples.length < 3) return null;
    
    const beforeChaos = this.samples[0];
    const duringChaos = this.samples[Math.floor(this.samples.length / 2)];
    const afterChaos = this.samples[this.samples.length - 1];
    
    return {
      before: beforeChaos.distribution,
      during: duringChaos.distribution,
      after: afterChaos.distribution,
      traffic_shifted: this.calculateTrafficShift(beforeChaos, duringChaos)
    };
  }
}
```

### Step 3: Single Endpoint Chaos Test
Test system response to chaos on one endpoint:
```javascript
async testSingleEndpointChaos() {
  const targetEndpoint = 'mainnet.helius-rpc.com';
  console.log(`Starting chaos test on ${targetEndpoint}`);
  
  // Start traffic monitoring
  this.trafficMonitor.startMonitoring();
  
  // Measure baseline performance
  const baseline = await this.measureBaselinePerformance(60000); // 1 minute baseline
  
  // Enable chaos on target endpoint
  this.chaosAdapter.enableChaos({
    targetEndpoints: [targetEndpoint],
    failureRate: 0.3, // 30% failure rate
    faultTypes: ['TIMEOUT', 'ECONNRESET', 'SERVER_ERROR']
  });
  
  console.log('Chaos injection enabled - monitoring system response...');
  
  // Run test workload during chaos
  const chaosResults = await this.runTestWorkloadDuringChaos(300000); // 5 minutes with chaos
  
  // Disable chaos and measure recovery
  this.chaosAdapter.disableChaos();
  console.log('Chaos injection disabled - measuring recovery...');
  
  const recoveryResults = await this.measureRecoveryPerformance(120000); // 2 minutes recovery
  
  // Stop monitoring
  this.trafficMonitor.stopMonitoring();
  
  return {
    baseline: baseline,
    chaos_period: chaosResults,
    recovery_period: recoveryResults,
    traffic_analysis: this.trafficMonitor.getTrafficShiftAnalysis(),
    chaos_stats: this.chaosAdapter.getChaosStats()
  };
}

async runTestWorkloadDuringChaos(durationMs) {
  const startTime = Date.now();
  const results = {
    requests_attempted: 0,
    requests_successful: 0,
    circuit_breaker_trips: 0,
    endpoint_failures: new Map()
  };
  
  // Run consistent workload
  while (Date.now() - startTime < durationMs) {
    try {
      results.requests_attempted++;
      
      // Make test RPC call
      await this.rpcPool.call('getSlot', []);
      results.requests_successful++;
      
    } catch (error) {
      // Categorize failure
      const endpoint = this.extractEndpointFromError(error);
      if (endpoint) {
        results.endpoint_failures.set(endpoint, 
          (results.endpoint_failures.get(endpoint) || 0) + 1
        );
      }
      
      if (error.message.includes('circuit')) {
        results.circuit_breaker_trips++;
      }
    }
    
    await new Promise(resolve => setTimeout(resolve, 100)); // 10 rps
  }
  
  results.success_rate = results.requests_successful / results.requests_attempted;
  return results;
}
```

### Step 4: Circuit Breaker State Monitoring
Monitor circuit breaker transitions during chaos:
```javascript
class CircuitBreakerChaosMonitor {
  constructor(circuitBreaker) {
    this.circuitBreaker = circuitBreaker;
    this.transitions = [];
    this.tripCounts = new Map();
    this.recoveryTimes = [];
    this.monitoring = false;
  }
  
  startMonitoring() {
    this.monitoring = true;
    this.resetStats();
    
    this.circuitBreaker.on('stateChange', (from, to, endpoint) => {
      const transition = {
        timestamp: Date.now(),
        endpoint,
        from,
        to,
        reason: this.circuitBreaker.getLastError(endpoint)?.message
      };
      
      this.transitions.push(transition);
      
      if (to === 'OPEN') {
        this.tripCounts.set(endpoint, (this.tripCounts.get(endpoint) || 0) + 1);
        console.log(`Circuit breaker OPENED for ${endpoint}:`, transition.reason);
      } else if (from === 'HALF_OPEN' && to === 'CLOSED') {
        this.recordRecovery(endpoint, transition.timestamp);
        console.log(`Circuit breaker RECOVERED for ${endpoint}`);
      } else if (from === 'HALF_OPEN' && to === 'OPEN') {
        console.log(`Circuit breaker recovery FAILED for ${endpoint}`);
      }
    });
    
    console.log('Circuit breaker monitoring started');
  }
  
  recordRecovery(endpoint, timestamp) {
    // Find the last OPEN transition for this endpoint
    const lastOpen = [...this.transitions]
      .reverse()
      .find(t => t.endpoint === endpoint && t.to === 'OPEN');
    
    if (lastOpen) {
      const recoveryTime = timestamp - lastOpen.timestamp;
      this.recoveryTimes.push({
        endpoint,
        recoveryTimeMs: recoveryTime,
        openTimestamp: lastOpen.timestamp,
        closedTimestamp: timestamp
      });
    }
  }
  
  getRecoveryAnalysis() {
    if (this.recoveryTimes.length === 0) return null;
    
    const recoveryTimesMs = this.recoveryTimes.map(r => r.recoveryTimeMs);
    
    return {
      recoveries_total: this.recoveryTimes.length,
      avg_recovery_time_ms: recoveryTimesMs.reduce((a, b) => a + b, 0) / recoveryTimesMs.length,
      min_recovery_time_ms: Math.min(...recoveryTimesMs),
      max_recovery_time_ms: Math.max(...recoveryTimesMs),
      successful_recoveries: this.recoveryTimes.length,
      recovery_details: this.recoveryTimes
    };
  }
}
```

### Step 5: Automatic Recovery Validation
Test system recovery when chaos stops:
```javascript
async validateAutomaticRecovery(targetEndpoint) {
  console.log('Validating automatic recovery...');
  
  const recoveryStartTime = Date.now();
  
  // Wait for circuit breaker to open on target endpoint
  await this.waitForCircuitBreakerState(targetEndpoint, 'OPEN', 30000);
  console.log(`Circuit breaker opened for ${targetEndpoint}`);
  
  // Disable chaos
  this.chaosAdapter.disableChaos();
  console.log('Chaos disabled - monitoring recovery...');
  
  // Wait for half-open state
  const halfOpenTime = await this.waitForCircuitBreakerState(targetEndpoint, 'HALF_OPEN', 60000);
  if (!halfOpenTime) {
    throw new Error('Circuit breaker did not enter HALF_OPEN state within timeout');
  }
  
  // Wait for closed state (successful recovery)
  const closedTime = await this.waitForCircuitBreakerState(targetEndpoint, 'CLOSED', 60000);
  if (!closedTime) {
    throw new Error('Circuit breaker did not recover to CLOSED state within timeout');
  }
  
  const totalRecoveryTime = closedTime - recoveryStartTime;
  
  // Validate probe success
  const probeStats = this.circuitBreaker.getProbeStats(targetEndpoint);
  
  return {
    recovery_successful: true,
    total_recovery_time_ms: totalRecoveryTime,
    half_open_delay_ms: halfOpenTime - recoveryStartTime,
    probe_success_count: probeStats.successCount,
    probe_failure_count: probeStats.failureCount,
    final_state: this.circuitBreaker.getState(targetEndpoint)
  };
}

async waitForCircuitBreakerState(endpoint, targetState, timeoutMs) {
  return new Promise((resolve, reject) => {
    const startTime = Date.now();
    
    const checkState = () => {
      const currentState = this.circuitBreaker.getState(endpoint);
      
      if (currentState === targetState) {
        resolve(Date.now());
        return;
      }
      
      if (Date.now() - startTime > timeoutMs) {
        resolve(null); // Timeout
        return;
      }
      
      setTimeout(checkState, 1000); // Check every second
    };
    
    checkState();
  });
}
```

### Step 6: Overall System Impact Analysis
Measure system-wide impact during single endpoint chaos:
```javascript
analyzeSystemImpact(chaosResults) {
  const systemAnalysis = {
    chaos_effectiveness: {
      target_endpoint_failure_rate: this.calculateEndpointFailureRate(chaosResults.chaos_stats),
      chaos_requests_intercepted: chaosResults.chaos_stats.requestsIntercepted,
      faults_injected: chaosResults.chaos_stats.faultsInjected
    },
    system_resilience: {
      overall_success_rate: chaosResults.chaos_period.success_rate,
      traffic_shedding_effective: this.verifyTrafficShedding(chaosResults.traffic_analysis),
      circuit_breaker_protection: chaosResults.chaos_period.circuit_breaker_trips > 0,
      recovery_time_ms: chaosResults.recovery_period.total_recovery_time_ms
    },
    pass_gates: {
      chaos_injection_working: chaosResults.chaos_stats.faultsInjected > 0,
      overall_success_above_97pct: chaosResults.chaos_period.success_rate >= 0.97,
      traffic_shifted_away: this.verifyTrafficShedding(chaosResults.traffic_analysis),
      recovery_under_60s: chaosResults.recovery_period.total_recovery_time_ms <= 60000,
      circuit_breaker_opened: chaosResults.chaos_period.circuit_breaker_trips > 0
    }
  };
  
  systemAnalysis.all_gates_passed = Object.values(systemAnalysis.pass_gates)
    .every(gate => gate === true);
  
  return systemAnalysis;
}
```

## CLEAR SUCCESS CRITERIA
- Circuit breaker opens on target endpoint within expected failure threshold (6 failures)
- Overall system success rate ≥97% during single endpoint chaos
- Traffic sheds away from failed endpoint to healthy endpoints
- Automatic recovery occurs within 60 seconds after chaos stops
- Half-open probes succeed and circuit breaker closes

## REQUIREMENTS-BASED VALIDATION
- **Chaos Injection**: Faults successfully injected at HTTP adapter level
- **Failure Detection**: Circuit breaker opens within 6 failures on target endpoint
- **System Resilience**: ≥97% overall success with 30% failure rate on one endpoint
- **Traffic Shedding**: Measurable traffic shift away from failed endpoint
- **Recovery Speed**: Complete recovery within 60 seconds of chaos cessation
- **Probe Validation**: Half-open probes succeed when endpoint recovers

---

# PROMPT RN6-CORRECTED: Hot Address Stability with Resource Monitoring - COMPLETE

## SINGLE FOCUS
Validate RPC pool stability using hot address sampling with per-method latency tracking and socket monitoring

## EXPLICIT FILE PATHS
- **CREATE**: `scripts/test-hot-address-stability-corrected.js`
- **CREATE**: `scripts/hot-address-sampler-corrected.js`
- **CREATE**: `scripts/resource-monitor.js`
- **CREATE**: `data/hot-addresses-refreshed.json` (curated and recent)
- **CREATE**: `results/hot-address-stability-results.json` (output)
- **IMPORT**: RPC pool components with connection monitoring

## INCREMENTAL IMPLEMENTATION

### Step 1: Refreshed Hot Address List
Create recently validated hot address list with categorization:
```javascript
const refreshedHotAddresses = {
  high_volume_mints: [
    {
      address: 'So11111111111111111111111111111111111111112', // Wrapped SOL
      name: 'WSOL',
      type: 'native',
      last_verified: '2024-08-31',
      activity_level: 'extreme'
    },
    {
      address: 'DezXAZ8z7PnrnRJjz3wXBoRgixCa6xjnB7YaB1pPB263', // BONK
      name: 'BONK',
      type: 'meme',
      last_verified: '2024-08-31',
      activity_level: 'high'
    },
    {
      address: 'EKpQGSJtjMFqKZ9KQanSqYXRcF8fBopzLHYxdM65zcjm', // WIF
      name: 'WIF',
      type: 'meme',
      last_verified: '2024-08-31',
      activity_level: 'high'
    }
  ],
  active_pools: [
    {
      address: '58oQChx4yWmvKdwLLZzBi4ChoCc2fqCUWBkwMihLYQo2', // SOL/USDC Raydium
      name: 'SOL-USDC',
      dex: 'raydium',
      last_verified: '2024-08-31',
      activity_level: 'extreme'
    },
    {
      address: '7XawhbbxtsRcQA8KTkHT9f9nc6d69UwqCDh6U5EEbEmX', // BONK/SOL
      name: 'BONK-SOL',
      dex: 'raydium',
      last_verified: '2024-08-31',
      activity_level: 'high'
    }
  ],
  whale_wallets: [
    {
      address: 'GDyn7ukbuKXyN3BMe8HJyXB9qzD4h8rcPxrJ8mF4EUbf',
      name: 'High Volume Trader',
      type: 'trader',
      last_verified: '2024-08-31',
      activity_level: 'high'
    }
  ]
};
```

### Step 2: Rate-Limited Method Sampler
Create sampler with method-specific rate limiting and filtering:
```javascript
class HotAddressSamplerCorrected {
  constructor(hotAddresses, rpcPool) {
    this.addresses = hotAddresses;
    this.rpcPool = rpcPool;
    this.methodRotation = 0;
    this.methods = [
      {
        name: 'getAccountInfo',
        applicable: ['mints', 'pools', 'wallets'],
        params: (address) => [address, { encoding: 'base64' }],
        rateLimit: 10 // per minute
      },
      {
        name: 'getTokenLargestAccounts',
        applicable: ['mints'],
        params: (address) => [address],
        rateLimit: 5 // per minute
      },
      {
        name: 'getBalance',
        applicable: ['wallets'],
        params: (address) => [address, { commitment: 'processed' }],
        rateLimit: 15 // per minute
      },
      {
        name: 'getProgramAccounts',
        applicable: ['mints'],
        params: (address) => [
          'TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA', // SPL Token Program
          {
            filters: [
              { dataSize: 165 },
            ],
            dataSlice: { offset: 0, length: 32 }
          }
        ],
        rateLimit: 1, // per minute - heavy operation
        weight: 5 // Count as 5 requests for resource tracking
      }
    ];
    this.methodUsage = new Map();
    this.latencyByMethod = new Map();
  }
  
  getNextMethodForAddress(address, addressType) {
    const applicableMethods = this.methods.filter(method =>
      method.applicable.includes(addressType)
    );
    
    if (applicableMethods.length === 0) return null;
    
    // Find method that hasn't hit rate limit
    for (let i = 0; i < applicableMethods.length; i++) {
      const method = applicableMethods[this.methodRotation % applicableMethods.length];
      this.methodRotation++;
      
      if (this.canUseMethod(method)) {
        this.recordMethodUsage(method.name);
        return method;
      }
    }
    
    return null; // All methods rate limited
  }
  
  canUseMethod(method) {
    const now = Date.now();
    const usage = this.methodUsage.get(method.name) || { count: 0, resetTime: now + 60000 };
    
    // Reset counter if minute has passed
    if (now > usage.resetTime) {
      usage.count = 0;
      usage.resetTime = now + 60000;
    }
    
    return usage.count < method.rateLimit;
  }
  
  recordMethodUsage(methodName) {
    const now = Date.now();
    const usage = this.methodUsage.get(methodName) || { count: 0, resetTime: now + 60000 };
    usage.count++;
    this.methodUsage.set(methodName, usage);
  }
}
```

### Step 3: Resource Monitor with Socket Tracking
Monitor connection pool resources and socket usage:
```javascript
class ResourceMonitorCorrected {
  constructor(rpcPool, connectionPool) {
    this.rpcPool = rpcPool;
    this.connectionPool = connectionPool;
    this.baseline = this.captureResourceBaseline();
    this.samples = [];
    this.monitoring = false;
  }
  
  captureResourceBaseline() {
    return {
      timestamp: Date.now(),
      memory: process.memoryUsage(),
      sockets: this.getSocketStats(),
      heap_objects: this.estimateHeapObjects()
    };
  }
  
  getSocketStats() {
    return {
      active_connections: this.connectionPool.getActiveConnections(),
      idle_connections: this.connectionPool.getIdleConnections(),
      total_sockets: this.connectionPool.getTotalSockets(),
      sockets_per_host: this.connectionPool.getSocketsPerHost(),
      keep_alive_sockets: this.connectionPool.getKeepAliveStats(),
      pending_requests: this.connectionPool.getPendingRequests()
    };
  }
  
  estimateHeapObjects() {
    // Rough estimation of objects in heap
    const memUsage = process.memoryUsage();
    return {
      heap_used_mb: Math.round(memUsage.heapUsed / 1024 / 1024),
      heap_total_mb: Math.round(memUsage.heapTotal / 1024 / 1024),
      external_mb: Math.round(memUsage.external / 1024 / 1024)
    };
  }
  
  startContinuousMonitoring(intervalMs = 30000) { // 30 seconds
    this.monitoring = true;
    
    this.monitoringInterval = setInterval(() => {
      this.sampleResources();
    }, intervalMs);
    
    console.log('Resource monitoring started - sampling every 30 seconds');
  }
  
  sampleResources() {
    const sample = {
      timestamp: Date.now(),
      elapsed_minutes: (Date.now() - this.baseline.timestamp) / 60000,
      memory: process.memoryUsage(),
      sockets: this.getSocketStats(),
      heap_objects: this.estimateHeapObjects(),
      rpc_pool_stats: this.rpcPool.getStats()
    };
    
    // Calculate growth from baseline
    sample.growth = {
      rss_mb: Math.round((sample.memory.rss - this.baseline.memory.rss) / 1024 / 1024),
      heap_used_mb: Math.round((sample.memory.heapUsed - this.baseline.memory.heapUsed) / 1024 / 1024),
      socket_count: sample.sockets.total_sockets - this.baseline.sockets.total_sockets
    };
    
    // Calculate hourly growth rate
    sample.hourly_growth_rates = {
      rss_mb_per_hour: sample.growth.rss_mb / (sample.elapsed_minutes / 60),
      heap_mb_per_hour: sample.growth.heap_used_mb / (sample.elapsed_minutes / 60)
    };
    
    this.samples.push(sample);
    
    // Log warnings for resource issues
    this.checkResourceWarnings(sample);
    
    console.log('Resource sample:', {
      elapsed_min: sample.elapsed_minutes.toFixed(1),
      rss_growth_mb: sample.growth.rss_mb,
      rss_rate_mb_per_hour: sample.hourly_growth_rates.rss_mb_per_hour.toFixed(1),
      sockets: sample.sockets.total_sockets,
      pending: sample.sockets.pending_requests
    });
  }
  
  checkResourceWarnings(sample) {
    // Memory growth rate warning
    if (sample.hourly_growth_rates.rss_mb_per_hour > 12.5) {
      console.warn('High memory growth rate detected:', 
        sample.hourly_growth_rates.rss_mb_per_hour.toFixed(1), 'MB/hour');
    }
    
    // Socket explosion warning
    const maxSockets = Object.values(sample.sockets.sockets_per_host).reduce((sum, count) => sum + count, 0);
    const socketUtilization = sample.sockets.total_sockets / (maxSockets || 100);
    if (socketUtilization > 0.9) {
      console.warn('Socket pool near capacity:', (socketUtilization * 100).toFixed(1), '%');
    }
    
    // Pending requests backlog
    if (sample.sockets.pending_requests > 50) {
      console.warn('High pending request count:', sample.sockets.pending_requests);
    }
  }
  
  stopMonitoring() {
    if (this.monitoringInterval) {
      clearInterval(this.monitoringInterval);
      this.monitoring = false;
      console.log('Resource monitoring stopped');
    }
  }
}
```

### Step 4: Complete Per-Method Latency Trend Analysis
Track latency trends for each RPC method separately:
```javascript
class LatencyTrendAnalyzer {
  constructor() {
    this.methodLatencies = new Map();
    this.trendAnalysis = new Map();
  }
  
  recordLatency(method, latencyMs, addressType) {
    if (!this.methodLatencies.has(method)) {
      this.methodLatencies.set(method, []);
    }
    
    this.methodLatencies.get(method).push({
      timestamp: Date.now(),
      latency: latencyMs,
      addressType: addressType
    });
  }
  
  analyzeLatencyTrends() {
    const trends = {};
    
    for (const [method, latencies] of this.methodLatencies) {
      if (latencies.length < 10) {
        trends[method] = {
          status: 'insufficient_data',
          sample_count: latencies.length
        };
        continue;
      }
      
      const timeWindows = this.createTimeWindows(latencies, 300000); // 5-minute windows
      const trendSlope = this.calculateTrendSlope(timeWindows);
      const recentLatencies = latencies.slice(-Math.min(50, latencies.length));
      
      trends[method] = {
        sample_count: latencies.length,
        time_windows: timeWindows.length,
        p50_latency_ms: this.calculatePercentile(latencies.map(l => l.latency), 0.5),
        p95_latency_ms: this.calculatePercentile(latencies.map(l => l.latency), 0.95),
        p99_latency_ms: this.calculatePercentile(latencies.map(l => l.latency), 0.99),
        trend_slope_ms_per_hour: trendSlope.slope,
        trend_r_squared: trendSlope.rSquared,
        degrading: trendSlope.slope > 5, // >5ms/hour degradation
        significant_trend: trendSlope.rSquared > 0.7,
        recent_avg_latency: recentLatencies.reduce((sum, l) => sum + l.latency, 0) / recentLatencies.length,
        baseline_avg_latency: latencies.slice(0, Math.min(50, latencies.length))
          .reduce((sum, l) => sum + l.latency, 0) / Math.min(50, latencies.length)
      };
      
      // Calculate degradation percentage
      if (trends[method].baseline_avg_latency > 0) {
        trends[method].degradation_pct = ((trends[method].recent_avg_latency - trends[method].baseline_avg_latency) 
          / trends[method].baseline_avg_latency * 100).toFixed(1);
      }
    }
    
    return trends;
  }
  
  createTimeWindows(latencies, windowSizeMs) {
    if (latencies.length === 0) return [];
    
    const sortedLatencies = [...latencies].sort((a, b) => a.timestamp - b.timestamp);
    const windows = [];
    const startTime = sortedLatencies[0].timestamp;
    const endTime = sortedLatencies[sortedLatencies.length - 1].timestamp;
    
    for (let windowStart = startTime; windowStart < endTime; windowStart += windowSizeMs) {
      const windowEnd = windowStart + windowSizeMs;
      const windowLatencies = sortedLatencies.filter(l => 
        l.timestamp >= windowStart && l.timestamp < windowEnd
      );
      
      if (windowLatencies.length > 0) {
        const avgLatency = windowLatencies.reduce((sum, l) => sum + l.latency, 0) / windowLatencies.length;
        windows.push({
          start_time: windowStart,
          end_time: windowEnd,
          sample_count: windowLatencies.length,
          avg_latency: avgLatency,
          window_center: windowStart + (windowSizeMs / 2)
        });
      }
    }
    
    return windows;
  }
  
  calculateTrendSlope(timeWindows) {
    if (timeWindows.length < 3) {
      return { slope: 0, rSquared: 0, insufficient_data: true };
    }
    
    // Convert timestamps to hours for more meaningful slope
    const points = timeWindows.map(w => ({
      x: (w.window_center - timeWindows[0].window_center) / 3600000, // hours
      y: w.avg_latency
    }));
    
    // Linear regression calculation
    const n = points.length;
    const sumX = points.reduce((sum, p) => sum + p.x, 0);
    const sumY = points.reduce((sum, p) => sum + p.y, 0);
    const sumXY = points.reduce((sum, p) => sum + (p.x * p.y), 0);
    const sumXX = points.reduce((sum, p) => sum + (p.x * p.x), 0);
    const sumYY = points.reduce((sum, p) => sum + (p.y * p.y), 0);
    
    const slope = (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX);
    
    // Calculate R-squared
    const meanY = sumY / n;
    const ssTotal = points.reduce((sum, p) => sum + Math.pow(p.y - meanY, 2), 0);
    const ssResidual = points.reduce((sum, p) => {
      const predicted = slope * p.x + (sumY - slope * sumX) / n;
      return sum + Math.pow(p.y - predicted, 2);
    }, 0);
    
    const rSquared = ssTotal > 0 ? 1 - (ssResidual / ssTotal) : 0;
    
    return {
      slope: isNaN(slope) ? 0 : slope,
      rSquared: isNaN(rSquared) ? 0 : Math.max(0, rSquared),
      sample_windows: n
    };
  }
  
  calculatePercentile(values, percentile) {
    if (values.length === 0) return 0;
    
    const sorted = [...values].sort((a, b) => a - b);
    const index = Math.ceil(sorted.length * percentile) - 1;
    return sorted[Math.max(0, index)];
  }
  
  getMethodStabilityReport() {
    const trends = this.analyzeLatencyTrends();
    const report = {
      methods_analyzed: Object.keys(trends).length,
      degrading_methods: [],
      stable_methods: [],
      insufficient_data: [],
      overall_stability: true
    };
    
    for (const [method, data] of Object.entries(trends)) {
      if (data.status === 'insufficient_data') {
        report.insufficient_data.push(method);
      } else if (data.degrading && data.significant_trend) {
        report.degrading_methods.push({
          method,
          slope: data.trend_slope_ms_per_hour,
          degradation_pct: data.degradation_pct,
          p95_latency: data.p95_latency_ms
        });
        report.overall_stability = false;
      } else {
        report.stable_methods.push({
          method,
          p95_latency: data.p95_latency_ms,
          degradation_pct: data.degradation_pct || '0.0'
        });
      }
    }
    
    return report;
  }
}
```

### Step 5: Complete 4-Hour Stability Test Implementation
Run comprehensive stability test with proper validation:
```javascript
async run4HourStabilityTest() {
  const testDurationMs = 4 * 60 * 60 * 1000; // 4 hours
  const testStartTime = Date.now();
  
  console.log('Starting 4-hour hot address stability test...');
  
  // Initialize components
  const resourceMonitor = new ResourceMonitorCorrected(this.rpcPool, this.connectionPool);
  const latencyAnalyzer = new LatencyTrendAnalyzer();
  const sampler = new HotAddressSamplerCorrected(this.hotAddresses, this.rpcPool);
  
  // Start monitoring
  resourceMonitor.startContinuousMonitoring();
  
  // Test statistics
  const testStats = {
    requests_attempted: 0,
    requests_successful: 0,
    requests_failed: 0,
    method_usage: new Map(),
    circuit_breaker_trips: 0
  };
  
  // Main test loop - consistent load
  while (Date.now() - testStartTime < testDurationMs) {
    const cycleStartTime = Date.now();
    
    try {
      // Select random hot address
      const addressCategory = this.selectRandomAddressCategory();
      const address = this.selectRandomAddressFromCategory(addressCategory);
      const method = sampler.getNextMethodForAddress(address.address, addressCategory);
      
      if (!method) {
        // All methods rate limited, wait
        await new Promise(resolve => setTimeout(resolve, 1000));
        continue;
      }
      
      testStats.requests_attempted++;
      const methodUsage = testStats.method_usage.get(method.name) || 0;
      testStats.method_usage.set(method.name, methodUsage + 1);
      
      // Make RPC call and measure latency
      const rpcStartTime = Date.now();
      
      try {
        const params = method.params(address.address);
        await this.rpcPool.call(method.name, params);
        
        const latency = Date.now() - rpcStartTime;
        latencyAnalyzer.recordLatency(method.name, latency, addressCategory);
        testStats.requests_successful++;
        
      } catch (rpcError) {
        const latency = Date.now() - rpcStartTime;
        latencyAnalyzer.recordLatency(method.name, latency, addressCategory);
        testStats.requests_failed++;
        
        if (rpcError.message.includes('circuit')) {
          testStats.circuit_breaker_trips++;
        }
        
        console.log(`RPC error for ${method.name}:`, rpcError.message);
      }
      
    } catch (error) {
      console.error('Test loop error:', error.message);
      testStats.requests_failed++;
    }
    
    // Maintain consistent request rate (~1 request per 5 seconds)
    const cycleTime = Date.now() - cycleStartTime;
    const targetCycleTime = 5000;
    if (cycleTime < targetCycleTime) {
      await new Promise(resolve => setTimeout(resolve, targetCycleTime - cycleTime));
    }
  }
  
  // Stop monitoring and analyze results
  resourceMonitor.stopMonitoring();
  
  console.log('4-hour test completed, generating analysis...');
  return this.generateStabilityReport(testStats, resourceMonitor, latencyAnalyzer);
}

generateStabilityReport(testStats, resourceMonitor, latencyAnalyzer) {
  const finalSample = resourceMonitor.samples[resourceMonitor.samples.length - 1];
  const stabilityReport = latencyAnalyzer.getMethodStabilityReport();
  
  // Memory stability analysis
  const memoryStable = finalSample.hourly_growth_rates.rss_mb_per_hour <= 12.5;
  const maxMemoryGrowth = Math.max(...resourceMonitor.samples.map(s => s.growth.rss_mb));
  
  // Latency stability analysis
  const latencyTrends = latencyAnalyzer.analyzeLatencyTrends();
  const anyDegradingTrends = Object.values(latencyTrends).some(trend => 
    trend.degrading && trend.significant_trend
  );
  
  // Success rate analysis
  const successRate = testStats.requests_successful / testStats.requests_attempted;
  
  const report = {
    test_summary: {
      duration_hours: 4,
      start_time: new Date(Date.now() - 4 * 60 * 60 * 1000).toISOString(),
      end_time: new Date().toISOString(),
      requests_attempted: testStats.requests_attempted,
      requests_successful: testStats.requests_successful,
      overall_success_rate_pct: Math.round(successRate * 100)
    },
    memory_analysis: {
      final_growth_mb: finalSample.growth.rss_mb,
      hourly_growth_rate_mb: finalSample.hourly_growth_rates.rss_mb_per_hour.toFixed(2),
      max_growth_during_test_mb: maxMemoryGrowth,
      memory_stable: memoryStable,
      baseline_rss_mb: Math.round(resourceMonitor.baseline.memory.rss / 1024 / 1024),
      final_rss_mb: Math.round(finalSample.memory.rss / 1024 / 1024)
    },
    latency_analysis: {
      methods_analyzed: stabilityReport.methods_analyzed,
      stable_methods: stabilityReport.stable_methods,
      degrading_methods: stabilityReport.degrading_methods,
      insufficient_data: stabilityReport.insufficient_data,
      latency_stable: stabilityReport.overall_stability,
      detailed_trends: latencyTrends
    },
    socket_analysis: {
      baseline_sockets: resourceMonitor.baseline.sockets.total_sockets,
      final_sockets: finalSample.sockets.total_sockets,
      max_pending_requests: Math.max(...resourceMonitor.samples.map(s => s.sockets.pending_requests)),
      socket_growth: finalSample.growth.socket_count,
      keep_alive_working: finalSample.sockets.keep_alive_sockets > 0
    },
    circuit_breaker_analysis: {
      trips_total: testStats.circuit_breaker_trips,
      trips_per_hour: testStats.circuit_breaker_trips / 4,
      trip_rate_acceptable: (testStats.circuit_breaker_trips / 4) <= 10
    },
    method_usage_distribution: Object.fromEntries(testStats.method_usage)
  };
  
  // Overall pass/fail gates
  report.pass_gates = {
    success_rate_above_95pct: successRate >= 0.95,
    memory_growth_under_50mb: maxMemoryGrowth <= 50,
    memory_rate_under_12_5mb_per_hour: finalSample.hourly_growth_rates.rss_mb_per_hour <= 12.5,
    no_significant_latency_degradation: !anyDegradingTrends,
    circuit_breaker_trips_acceptable: (testStats.circuit_breaker_trips / 4) <= 10,
    socket_growth_controlled: Math.abs(finalSample.growth.socket_count) <= 20
  };
  
  report.overall_pass = Object.values(report.pass_gates).every(gate => gate === true);
  
  return report;
}

// Helper methods for test execution
selectRandomAddressCategory() {
  const categories = ['high_volume_mints', 'active_pools', 'whale_wallets'];
  return categories[Math.floor(Math.random() * categories.length)];
}

selectRandomAddressFromCategory(category) {
  const addresses = this.hotAddresses[category];
  return addresses[Math.floor(Math.random() * addresses.length)];
}
```

### Step 6: Final Integration and Validation
Complete test orchestration with clear pass/fail criteria:
```javascript
class HotAddressStabilityTestCorrected {
  constructor(rpcPool, connectionPool, circuitBreaker) {
    this.rpcPool = rpcPool;
    this.connectionPool = connectionPool;
    this.circuitBreaker = circuitBreaker;
    this.hotAddresses = refreshedHotAddresses;
  }
  
  async executeCompleteTest() {
    console.log('=== Hot Address Stability Test - Complete Validation ===');
    
    try {
      // Pre-test validation
      await this.validateTestPreconditions();
      
      // Execute 4-hour stability test
      const results = await this.run4HourStabilityTest();
      
      // Generate comprehensive report
      const finalReport = this.generateFinalValidationReport(results);
      
      // Save results
      await this.saveResults(finalReport);
      
      console.log('=== Test Complete ===');
      console.log('Overall Result:', finalReport.overall_pass ? 'PASS' : 'FAIL');
      
      return finalReport;
      
    } catch (error) {
      console.error('Stability test failed:', error);
      return {
        test_status: 'FAILED',
        error: error.message,
        overall_pass: false
      };
    }
  }
  
  async validateTestPreconditions() {
    // Verify RPC pool is healthy
    const poolHealth = await this.rpcPool.checkHealth();
    if (!poolHealth.healthy) {
      throw new Error('RPC pool not healthy before test start');
    }
    
    // Verify hot addresses are accessible
    for (const category of Object.keys(this.hotAddresses)) {
      const firstAddress = this.hotAddresses[category][0];
      try {
        await this.rpcPool.call('getAccountInfo', [firstAddress.address]);
        console.log(`Validated access to ${category}: ${firstAddress.name}`);
      } catch (error) {
        console.warn(`Cannot access ${firstAddress.name}:`, error.message);
      }
    }
    
    console.log('Pre-test validation complete');
  }
  
  generateFinalValidationReport(testResults) {
    const report = {
      ...testResults,
      test_metadata: {
        test_type: 'hot_address_stability',
        duration_hours: 4,
        completion_time: new Date().toISOString(),
        version: 'corrected_v1'
      },
      validation_summary: {
        memory_validation: testResults.pass_gates.memory_growth_under_50mb && 
                          testResults.pass_gates.memory_rate_under_12_5mb_per_hour,
        performance_validation: testResults.pass_gates.no_significant_latency_degradation &&
                               testResults.pass_gates.success_rate_above_95pct,
        stability_validation: testResults.pass_gates.circuit_breaker_trips_acceptable &&
                             testResults.pass_gates.socket_growth_controlled,
        overall_system_stable: testResults.overall_pass
      },
      recommendations: this.generateRecommendations(testResults)
    };
    
    return report;
  }
  
  generateRecommendations(testResults) {
    const recommendations = [];
    
    if (!testResults.pass_gates.memory_growth_under_50mb) {
      recommendations.push({
        category: 'memory',
        severity: 'high',
        issue: `Memory growth ${testResults.memory_analysis.max_growth_during_test_mb}MB exceeds 50MB limit`,
        action: 'Investigate memory leaks in connection pooling or caching'
      });
    }
    
    if (!testResults.pass_gates.no_significant_latency_degradation) {
      recommendations.push({
        category: 'performance',
        severity: 'medium',
        issue: 'Latency degradation detected in one or more methods',
        action: 'Review degrading methods and optimize or add circuit breaker protection'
      });
    }
    
    if (!testResults.pass_gates.success_rate_above_95pct) {
      recommendations.push({
        category: 'reliability',
        severity: 'high',
        issue: `Success rate ${testResults.test_summary.overall_success_rate_pct}% below 95%`,
        action: 'Investigate RPC failures and improve error handling'
      });
    }
    
    if (recommendations.length === 0) {
      recommendations.push({
        category: 'validation',
        severity: 'info',
        issue: 'All stability tests passed',
        action: 'System ready for production deployment'
      });
    }
    
    return recommendations;
  }
  
  async saveResults(report) {
    const filename = `hot-address-stability-${new Date().toISOString().split('T')[0]}.json`;
    try {
      // Save to results directory
      console.log(`Saving results to: results/${filename}`);
      // Implementation would save to file system
    } catch (error) {
      console.warn('Failed to save results:', error.message);
    }
  }
}
```

## CLEAR SUCCESS CRITERIA
- **Memory Stability**: RSS growth ≤50MB total AND ≤12.5MB/hour sustained rate
- **Performance Stability**: No significant latency degradation (>5ms/hour with R² > 0.7)
- **Success Rate**: ≥95% of RPC requests successful over 4 hours
- **Circuit Breaker**: ≤10 trips per hour with successful recovery
- **Socket Stability**: Socket count growth ≤±20 connections from baseline

## REQUIREMENTS-BASED VALIDATION
- **Memory Efficiency**: Hourly growth rate monitoring prevents long-term memory leaks
- **Latency Trends**: Per-method trend analysis with statistical significance
- **Resource Monitoring**: Socket pool and connection management validation
- **Method Coverage**: All RPC methods tested with appropriate rate limiting
- **Long-term Stability**: 4-hour sustained load proves 24/7 operation capability
- **Comprehensive Reporting**: Actionable recommendations based on test results