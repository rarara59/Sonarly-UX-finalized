PROMPT 1F: Batch Manager Extraction
SINGLE FOCUS: Extract request batching logic from existing 2000-line RPC connection pool
EXPLICIT FILE PATHS:

Source: src/detection/transport/rpc-connection-pool.js (batch, aggregate, group sections)
Target: src/detection/transport/batch-manager.js

INCREMENTAL IMPLEMENTATION PROCESS:
Step 1: Extract batch accumulation, timing trigger, and response routing logic
Step 2: Create BatchManager class with request batching, timeout triggers, and response splitting
Step 3: Test batch size and timeout triggers in isolation with controllable request timing
Step 4: Test response routing accuracy (ensure each caller gets correct response from batch)
Step 5: Create integration stub in original file: await this.batchManager.addRequest(method, params)
CLEAR SUCCESS CRITERIA:
Batching Requirements:

Batch efficiency: 80%+ reduction in actual RPC calls for batchable request types
Timing accuracy: Batches sent within 5% of configured timeout duration
Size limits: Respects maximum batch size limits and never exceeds configured maximums
Response routing: 100% accurate routing of individual responses to correct Promise resolvers

Performance Requirements:

Batch formation time: <10ms overhead per request added to current batch
Memory per batch: <1KB memory overhead regardless of batch size up to maximum
Timeout accuracy: Flush pending batch within 10ms of configured timeout
Concurrency safety: Handle 1000 concurrent addRequest() calls without corruption

Integration Requirements:

Original file compiles successfully after extraction with integration stub
Integration interface: await this.batchManager.addRequest(method, params) ready for orchestrator
Export functionality: import { BatchManager } from './batch-manager.js' works correctly
Configuration compatibility: Existing batch size and timeout environment variables preserved

REQUIREMENTS-BASED VALIDATION:
Measure These Metrics:

RPC call reduction percentage (target: 80%+ reduction for batchable requests)
Timeout accuracy (target: Within 10ms of configured timeout for batch flushing)
Response routing accuracy (target: 100% correct Promise resolution to original callers)
Memory efficiency per batch (target: <1KB overhead per batch regardless of size)
Batch formation latency (target: <10ms per request added to batch)